{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Character-level language modeling in TensorFlow\n",
    "Language modeling is a fascinating application that enables machines to perform human language-related tasks, such as generating English sentences. One of the interesting studies in this area is Generating Text with Recurrent Neural Networks, Ilya Sutskever, James Martens, and Geoffrey E. Hinton, Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, \n",
    "https://pdfs.semanticscholar.org/93c2/0e38c85b69fc2d2eb314b3c1217913f7db11.pdf)\n",
    "\n",
    "In the model that we will build now, the input is a text document, and our goal is\n",
    "to develop a model that can generate new text that is similar in style to the input document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567 1112917\n",
      "Total Length: 1112350\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "## Reading and processing text\n",
    "with open('1268-0.txt', 'r') as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "print(start_indx, end_indx)\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading and preprocessing the text, we have a sequence consisting of 1,112,350 characters in total and 80 unique characters. However, most NN libraries and RNN implementations cannot deal with input data in string format, which is why we have to convert the text into a numeric format. To do this, we will create\n",
    "a simple Python dictionary that maps each character to an integer, char2int. We will also need a reverse mapping to convert the results of our model back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1112350,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 32 29  1 37 48 43 44 29 42 33 39 45 43  1 33 43 36 25 38 28  1  6  6\n",
      "  6  0  0  0  0  0 40 67 64 53 70 52 54 53  1 51]  ->  74\n",
      "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'  ->  'y'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "## inspection:\n",
    "for seq in ds_chunks.take(1):\n",
    "    input_seq = seq[:seq_length].numpy()\n",
    "    target = seq[seq_length].numpy()\n",
    "    print(input_seq, ' -> ', target)\n",
    "    print(repr(''.join(char_array[input_seq])), \n",
    "          ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x): ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "Target (y): 'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## define the function for splitting x & y\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)\n",
    "\n",
    "## inspection:\n",
    "for example in ds_sequences.take(2):\n",
    "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 40), (None, 40)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)# drop_remainder=True)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a character-level RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(\n",
    "            rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size = charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 411s 970ms/step - loss: 2.3011\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 405s 954ms/step - loss: 1.7332\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 379s 893ms/step - loss: 1.5343\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 390s 919ms/step - loss: 1.4204\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 379s 895ms/step - loss: 1.3477\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 384s 906ms/step - loss: 1.2976\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 377s 888ms/step - loss: 1.2597\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 357s 841ms/step - loss: 1.2286\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 352s 831ms/step - loss: 1.2030\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 341s 803ms/step - loss: 1.1817\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 360s 850ms/step - loss: 1.1618\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 333s 785ms/step - loss: 1.1445\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 450s 1s/step - loss: 1.1282\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 405s 954ms/step - loss: 1.1126\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 401s 945ms/step - loss: 1.0985\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 405s 955ms/step - loss: 1.0845\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 391s 923ms/step - loss: 1.0717\n",
      "Epoch 18/20\n",
      "424/424 [==============================] - 486s 1s/step - loss: 1.0589\n",
      "Epoch 19/20\n",
      "424/424 [==============================] - 384s 906ms/step - loss: 1.0459\n",
      "Epoch 20/20\n",
      "424/424 [==============================] - 379s 895ms/step - loss: 1.0337\n",
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n",
      "Probabilities: [0.10650698 0.10650698 0.78698605]\n",
      "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    ))\n",
    "\n",
    "model.fit(ds, epochs=20)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island is open he heard the vessel towards his arm and his brows of the love of the island had been long more so, the storm is gratitude his fear absence, whose arms, a few minutes as if heard swallowed the\n",
      "trees which Gideon Spilett in the next day, the grain was floating for simply\n",
      "honest men. This led by\n",
      "the occasion concealed by the\n",
      "colonists’ ro.”\n",
      "\n",
      "said the reporter.\n",
      "\n",
      "“Look all,” said Pencroft, “we have made knocks, uneasy to this case and thunding\n",
      "became themselves in the turn at the boat.\n",
      "\n",
      "The \n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           max_input_length=40,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(\n",
    "            scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        \n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat(\n",
    "            [encoded_input, new_char_indx],\n",
    "            axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "\n",
    "    return generated_str\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:         [0.10650698 0.10650698 0.78698604]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611688]\n",
      "Probabilities after scaling with 0.1: [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:        ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:', tf.math.softmax(0.5*logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:', tf.math.softmax(0.1*logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was so as to contracted the plateau of Prospect Heights were still remained to be feared that the powder and the light of the colonists and a half aroused the colonists with the channel it was not a document wished to penetrate into the shore.\n",
      "\n",
      "The colonists listened the convicts had not been able to prevent them her\n",
      "anchor to the settlers’ reason for the night of the water. There were the new was only to the corral, or rather the first point of the Mercy, and the next day, the lad served to th\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island\n",
      "happilid a drelugianeor\n",
      "wished, volcanic\n",
      "quallable. Anotremity of you, my Jatap, toie glet to imagine Melbowarious. Pencroft had behveld il and progumpts and on a doblas’s orcoon Basual o’clock, it\n",
      "rather his teibin, victled a quarter. Wherefolded brhatquir, holds nood, makinques.\n",
      "\n",
      "Gideon Splinforted\n",
      "opened\n",
      "for\n",
      "he of\n",
      "EdAlitantis Jap, Oneto”\n",
      "is\n",
      "will\n",
      "be more to woromoh?-”\n",
      "\n",
      "nanglion, my 60:\n",
      "Nejo.’”\n",
      "\n",
      "Gideon Spilett toold how they who becake at watric bea-drew opprooganding his-ope weigle mack strie\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
